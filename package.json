{
  "name": "@loonylabs/llm-middleware",
  "version": "2.1.0",
  "description": "Complete middleware infrastructure for LLM-based backends with multi-provider support (Ollama, Anthropic, OpenAI, Google)",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "scripts": {
    "start": "ts-node src/examples/simple-chat/index.ts",
    "dev": "ts-node-dev --inspect --respawn src/examples/simple-chat/index.ts",
    "build": "tsc",
    "test": "npm run test:unit",
    "test:all": "npm run test:unit && npm run test:basic && npm run test:integration && npm run test:integration:parameters && npm run test:robustness",
    "test:unit": "jest",
    "test:unit:watch": "jest --watch",
    "test:unit:coverage": "jest --coverage",
    "test:basic": "node tests/basic/test-middleware.js",
    "test:integration": "node tests/integration/test-flat-formatter.js",
    "test:integration:parameters": "node tests/integration/test-parameter-limits.js",
    "test:robustness": "node tests/robustness/test-json-handling.js",
    "test:e2e": "node tests/e2e/test-workflow.js",
    "test:manual:smoke": "ts-node tests/manual/smoke-test.ts",
    "test:manual:verify-params": "node tests/manual/verify-parameters.js",
    "test:manual:formatter-demo": "ts-node tests/manual/request-formatter-demo.ts",
    "test:manual:story-test": "ts-node tests/manual/story-generator-test.ts",
    "test:provider:ollama": "TEST_PROVIDER=ollama ts-node tests/manual/provider-smoke-test.ts",
    "test:provider:anthropic": "TEST_PROVIDER=anthropic ts-node tests/manual/provider-smoke-test.ts",
    "test:ci": "jest --runInBand --ci --coverage",
    "lint": "eslint src/**/*.ts",
    "clean": "rm -rf dist",
    "prepare": "npm run build",
    "prepublishOnly": "npm run clean && npm run build && npm run test"
  },
  "keywords": [
    "llm",
    "middleware",
    "ai",
    "ollama",
    "openai",
    "anthropic",
    "google",
    "multi-provider",
    "backend",
    "typescript",
    "express",
    "json-cleaner",
    "logging",
    "chatbot",
    "api",
    "async",
    "streaming",
    "response-processing"
  ],
  "author": "loonylabs-dev",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/loonylabs-dev/llm-middleware.git"
  },
  "bugs": {
    "url": "https://github.com/loonylabs-dev/llm-middleware/issues"
  },
  "homepage": "https://github.com/loonylabs-dev/llm-middleware#readme",
  "dependencies": {
    "axios": "^1.7.9",
    "cors": "^2.8.5",
    "dotenv": "^16.4.7",
    "express": "^4.18.2",
    "gpt-tokenizer": "^3.2.0",
    "uuid": "^11.1.0"
  },
  "devDependencies": {
    "@types/cors": "^2.8.17",
    "@types/express": "^4.17.21",
    "@types/jest": "^29.5.14",
    "@types/node": "^22.10.2",
    "@types/uuid": "^10.0.0",
    "@typescript-eslint/eslint-plugin": "^6.0.0",
    "@typescript-eslint/parser": "^6.0.0",
    "eslint": "^8.45.0",
    "jest": "^29.7.0",
    "nodemon": "^3.1.9",
    "ts-jest": "^29.3.4",
    "ts-node": "^10.9.2",
    "ts-node-dev": "^2.0.0",
    "typescript": "^5.7.2"
  },
  "engines": {
    "node": ">=18.0.0"
  },
  "files": [
    "dist",
    "README.md",
    "LICENSE",
    ".env.example"
  ],
  "publishConfig": {
    "access": "public"
  }
}
