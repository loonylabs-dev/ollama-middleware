# Server Configuration
PORT=3000
NODE_ENV=development

# Logging Configuration
LOG_LEVEL=info

# LLM Provider Configuration (Ollama Example)
# IMPORTANT: MODEL1_NAME is REQUIRED for the middleware to work
MODEL1_NAME=phi3:mini                  # Required: Your model name (e.g., phi3:mini, llama3:8b, gemma2:2b)
MODEL1_URL=http://localhost:11434     # Optional: Defaults to localhost:11434 (Ollama default)
MODEL1_TOKEN=your_model1_token_here    # Optional: For authenticated providers

# Authentication (Optional)
AUTH_VALIDATION_TYPE=none
STATIC_API_KEY=your_static_api_key_here

# Database Logging (Optional)
SUPABASE_URL=your_supabase_url_here
SUPABASE_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_KEY=your_supabase_service_key_here