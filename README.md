<div align="center">

# ğŸš€ Ollama Middleware

*A comprehensive TypeScript middleware library for building robust Ollama-based AI backends with advanced features like JSON cleaning, logging, error handling, and more.*

<!-- Horizontal Badge Navigation Bar -->
[![GitHub Install](https://img.shields.io/badge/Install-GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](#-quick-start)
[![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-blue.svg?style=for-the-badge&logo=typescript&logoColor=white)](#-features)
[![Node.js](https://img.shields.io/badge/Node.js-18+-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)](#-prerequisites)
[![Docker Ready](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker&logoColor=white)](#-quick-start)
[![API Documentation](https://img.shields.io/badge/API-Documented-FF6B35?style=for-the-badge&logo=swagger&logoColor=white)](#-documentation)
[![Test Coverage](https://img.shields.io/badge/Tests-Comprehensive-4CAF50?style=for-the-badge&logo=jest&logoColor=white)](#-testing-and-examples)
[![MIT License](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge&logo=opensource&logoColor=white)](#-license)

</div>

<!-- Table of Contents -->
<details>
<summary>ğŸ“‹ <strong>Table of Contents</strong></summary>

- [âœ¨ Features](#-features)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“‹ Prerequisites](#-prerequisites)
- [âš™ï¸ Configuration](#ï¸-configuration)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“– Documentation](#-documentation)
- [ğŸ§ª Testing and Examples](#-testing-and-examples)
- [ğŸ”§ Advanced Features](#-advanced-features)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)
- [ğŸ™ Acknowledgments](#-acknowledgments)
- [ğŸ”— Links](#-links)

</details>

---

## âœ¨ Features

- ğŸ—ï¸ **Clean Architecture**: Base classes and interfaces for scalable AI applications
- ğŸ¤– **Ollama Integration**: Complete service layer with retry logic and authentication
- ğŸ§¹ **JSON Cleaning**: Advanced JSON repair and validation system
- ğŸ¨ **FlatFormatter System**: Advanced data formatting for LLM consumption
- ğŸ“Š **Comprehensive Logging**: Multi-level logging with metadata support
- âš™ï¸ **Configuration Management**: Flexible model and application configuration
- ğŸ›¡ï¸ **Error Handling**: Robust error handling and recovery mechanisms
- ğŸ”§ **TypeScript First**: Full type safety throughout the entire stack
- ğŸ“¦ **Modular Design**: Use only what you need
- ğŸ§ª **Testing Ready**: Includes example implementations and test utilities

## ğŸš€ Quick Start

### Installation

Install directly from GitHub:

```bash
npm install git+https://github.com/planichttm/ollama-middleware.git
```

Or using a specific version/tag:

```bash
npm install git+https://github.com/planichttm/ollama-middleware.git#v1.0.0
```

### Basic Usage

```typescript
import { BaseAIUseCase, BaseAIRequest, BaseAIResult } from 'ollama-middleware';

// Define your request/response interfaces
interface MyRequest extends BaseAIRequest {
  message: string;
}

interface MyResult extends BaseAIResult {
  response: string;
}

// Create your use case
class MyChatUseCase extends BaseAIUseCase<MyRequest, MyResult> {
  protected readonly systemMessage = "You are a helpful assistant.";
  
  protected formatUserMessage(prompt: any): string {
    return prompt.message;
  }
  
  protected createResult(content: string, usedPrompt: string, thinking?: string): MyResult {
    return {
      generatedContent: content,
      model: this.modelConfig.name,
      usedPrompt: usedPrompt,
      thinking: thinking,
      response: content
    };
  }
}
```

<details>
<summary><strong>ğŸ­ Advanced Character Generation Example</strong></summary>

```typescript
import { 
  FlatFormatter, 
  LLMContextBuilder,
  characterPreset,
  genrePreset,
  settingPreset 
} from 'ollama-middleware';

class CharacterGeneratorUseCase {
  protected readonly systemMessage = `You are an expert character creator.
  
IMPORTANT: Respond with ONLY valid JSON following this schema:
{
  "Name": "Character name",
  "Age": "Character age", 
  "Description": "Brief character overview",
  "Personality": "Core personality traits",
  "Background": "Character history",
  "Goals": "What they want to achieve",
  "Conflicts": "Internal and external conflicts"
}`;

  // Use FlatFormatter and presets for rich context building
  protected formatUserMessage(prompt: any): string {
    const { role, setting, genre, constraints } = prompt;
    
    const contextSections = [
      `## CHARACTER ROLE: ${role}`,
      settingPreset.formatForLLM(setting, "## STORY SETTING:"),
      genrePreset.formatForLLM(genre, "## GENRE REQUIREMENTS:"),
      
      // Format constraints with FlatFormatter
      FlatFormatter.flatten(
        constraints.map(constraint => ({ 
          constraint: constraint,
          priority: "MUST FOLLOW" 
        })),
        {
          format: 'numbered',
          entryTitleKey: 'constraint',
          ignoredKeys: ['constraint']
        }
      )
    ];
    
    return contextSections.join('\n\n');
  }
}
  
  protected createResult(content: string, usedPrompt: string, thinking?: string): MyResult {
    return {
      generatedContent: content,
      model: this.modelConfig.name,
      usedPrompt,
      thinking,
      response: content
    };
  }
}

// Use it
const chatUseCase = new MyChatUseCase();
const result = await chatUseCase.execute({ 
  prompt: { message: "Hello!" },
  authToken: "optional-token"
});
```

</details>

## ğŸ“‹ Prerequisites

<details>
<summary><strong>ğŸ“¦ Required Dependencies</strong></summary>

- **Node.js** 18+
- **TypeScript** 4.9+
- **Ollama server** running (local or remote)

</details>

## âš™ï¸ Configuration

<details>
<summary><strong>ğŸ”§ Environment Setup</strong></summary>

Create a `.env` file in your project root:

```env
# Server Configuration
PORT=3000
NODE_ENV=development

# Logging
LOG_LEVEL=info

# Ollama Model Configuration
MODEL1_URL=http://localhost:11434
MODEL1_NAME=mistral:latest
MODEL1_TOKEN=optional-auth-token
```

</details>

## ğŸ—ï¸ Architecture

The middleware follows **Clean Architecture** principles:

```
src/
â”œâ”€â”€ middleware/
â”‚   â”œâ”€â”€ controllers/base/     # Base HTTP controllers
â”‚   â”œâ”€â”€ usecases/base/        # Base AI use cases
â”‚   â”œâ”€â”€ services/             # External service integrations
â”‚   â”‚   â”œâ”€â”€ ollama/          # Ollama API service
â”‚   â”‚   â”œâ”€â”€ json-cleaner/    # JSON repair and validation
â”‚   â”‚   â””â”€â”€ response-processor/ # AI response processing
â”‚   â””â”€â”€ shared/              # Common utilities and types
â”‚       â”œâ”€â”€ config/          # Configuration management
â”‚       â”œâ”€â”€ types/           # TypeScript interfaces
â”‚       â””â”€â”€ utils/           # Utility functions
â””â”€â”€ examples/               # Example implementations
    â””â”€â”€ simple-chat/        # Basic chat example
```

## ğŸ“– Documentation

- [Getting Started Guide](docs/GETTING_STARTED.md)
- [Architecture Overview](docs/ARCHITECTURE.md)
- [API Reference](docs/API_REFERENCE.md)
- [Examples](docs/EXAMPLES.md)

## ğŸ§ª Testing and Examples

### ğŸƒâ€â™‚ï¸ Run Built-in Tests

The middleware includes comprehensive test suites:

```bash
# Build the middleware
npm run build

# Test basic components
node test-middleware.js

# Test complete End-to-End workflow  
node test-e2e-workflow.js

# Test robustness and error handling
node test-robustness.js

# Test FlatFormatter system
node test-flat-formatter.js
```

<details>
<summary><strong>ğŸ“Š Test Results Summary</strong></summary>

- âœ… **Component Tests**: All services working (JSON Cleaner, Response Processor, etc.)
- âœ… **E2E Workflow**: Complete pipeline from request to parsed result
- âœ… **JSON Robustness**: 80% success rate on malformed JSON repair
- âœ… **Error Handling**: 100% graceful handling of extreme scenarios
- âœ… **Performance**: Large JSON processing at 1.1M chars/second

</details>

### ğŸ¯ Example Application

<details>
<summary><strong>ğŸš€ Quick Example Setup</strong></summary>

Run the included examples:

```bash
# Clone the repository
git clone https://github.com/planichttm/ollama-middleware.git
cd ollama-middleware

# Install dependencies
npm install

# Copy environment template
cp .env.example .env

# Start Ollama (if running locally)
ollama serve

# Run the example
npm run dev
```

Test the API:
```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello, how are you?"}'
```

</details>

## ğŸ”§ Advanced Features

<details>
<summary><strong>ğŸ§¹ JSON Cleaning System</strong></summary>

Automatically repair malformed JSON responses from AI models:

```typescript
import { JsonCleanerService } from 'ollama-middleware';

const malformedJson = '{"key": "value",}'; // trailing comma
const cleaned = JsonCleanerService.processResponse(malformedJson);
console.log(cleaned.cleanedJson); // {"key": "value"}
```

</details>

<details>
<summary><strong>ğŸ“Š Comprehensive Logging</strong></summary>

Multi-level logging with contextual metadata:

```typescript
import { logger } from 'ollama-middleware';

logger.info('Operation completed', {
  context: 'MyService',
  metadata: { userId: 123, duration: 150 }
});
```

</details>

<details>
<summary><strong>âš™ï¸ Model Configuration</strong></summary>

Flexible model management:

```typescript
import { getModelConfig } from 'ollama-middleware';

const config = getModelConfig('MODEL1');
console.log(config.name);     // mistral:latest
console.log(config.baseUrl);  // http://localhost:11434
```

</details>

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) for the amazing local LLM platform
- The open-source community for inspiration and contributions

## ğŸ”— Links

- [ğŸ“š Documentation](https://github.com/planichttm/ollama-middleware/docs)
- [ğŸ› Issues](https://github.com/planichttm/ollama-middleware/issues)
- [ğŸ“¦ NPM Package](https://www.npmjs.com/package/ollama-middleware)

---

<div align="center">

**Made with â¤ï¸ for the AI community**

[![GitHub stars](https://img.shields.io/github/stars/planichttm/ollama-middleware?style=social)](https://github.com/planichttm/ollama-middleware/stargazers)
[![Follow on GitHub](https://img.shields.io/github/followers/planichttm?style=social&label=Follow)](https://github.com/planichttm)

</div>